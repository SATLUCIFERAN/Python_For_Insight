{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39945bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- The Prophet's Final Report ---\n",
      "Ticket: 'The axe handle snapped off after only one use.'\n",
      "Prophecy: 'Product Issue' (Confidence: 0.34) \n",
      "\n",
      "Ticket: 'How do I update my payment information?'\n",
      "Prophecy: 'Billing' (Confidence: 0.34) \n",
      "\n",
      "Ticket: 'I cannot find the scroll for my billing statement.'\n",
      "Prophecy: 'Missing Items' (Confidence: 0.34) \n",
      "\n",
      "Ticket: 'My sword sharpening kit is missing from my order.'\n",
      "Prophecy: 'Missing Items' (Confidence: 0.37) \n",
      "\n",
      "\n",
      "--- The Oracle's Final Judgement ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Billing       1.00      0.50      0.67         2\n",
      "Missing Items       0.50      1.00      0.67         1\n",
      "Product Issue       1.00      1.00      1.00         1\n",
      "\n",
      "     accuracy                           0.75         4\n",
      "    macro avg       0.83      0.83      0.78         4\n",
      " weighted avg       0.88      0.75      0.75         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. First, we load our essential tools from the scikit-learn library.\n",
    "# We're importing a tool to transform words into numbers (TfidfVectorizer),\n",
    "# a simple and effective prophetic model (LogisticRegression),\n",
    "# and tools to help us evaluate how good our prophecy is (train_test_split, classification_report).\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np \n",
    "\n",
    "# We'll use this list to store our raw support tickets and their correct tags.\n",
    "# This is our training data, the historical scrolls from which our prophet will learn.\n",
    "\n",
    "data = [\n",
    "    (\"My sword sharpening kit is missing from my order.\",\n",
    "     \"Missing Items\"),\n",
    "    (\"I cannot find the scroll for my billing statement.\", \n",
    "     \"Billing\"),\n",
    "    (\"The dragon-proof shield I ordered has a dent in it.\", \n",
    "     \"Product Issue\"),\n",
    "     \n",
    "    (\"There's an issue with my last bill, it seems too high.\", \n",
    "     \"Billing\"),\n",
    "    (\"The axe handle snapped off after only one use.\", \n",
    "     \"Product Issue\"),\n",
    "    (\"My order arrived, but the potion of strength is not here.\", \n",
    "     \"Missing Items\"),\n",
    "    (\"How do I update my payment information?\", \n",
    "     \"Billing\")\n",
    "]\n",
    "\n",
    "# Separate the raw text (our tickets) from the correct prophecy (our tags).\n",
    "documents = [d[0] for d in data]\n",
    "labels = [d[1] for d in data]\n",
    "\n",
    "\n",
    "# 2. Divide our scrolls into two piles: a training pile and a testing pile.\n",
    "# Our prophet will learn from the training pile and be tested on the testing pile\n",
    "# to ensure its prophecies are true, and not just lucky guesses.\n",
    "# NOTE: With only 7 samples, these metrics are for illustrative purposes only and\n",
    "# would be highly unstable in a real-world scenario.\n",
    "# The 'stratify=labels' parameter ensures our tiny dataset is split proportionally.\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, labels, test_size=0.5, random_state=42, stratify=labels)\n",
    "\n",
    "\n",
    "# 3. Cast the Vectorization spell!\n",
    "# This is where we create our TfidfVectorizer object, which will turn words into\n",
    "# magical numerical vectors. We'll use the 'ngram_range=(1, 2)' enchantment\n",
    "# to capture both single words and pairs of words. This adds context to our prophecy.\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# 4. Train our prophet.\n",
    "# We now create our prophetic model (Logistic Regression) and feed it our\n",
    "# vectorized training data and the correct answers (y_train).\n",
    "# We're using a specific solver and max_iter for better stability with small datasets.\n",
    "prophet = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "prophet.fit(X_train_vectorized, y_train)\n",
    "\n",
    "\n",
    "# 5. Test our prophet on new scrolls and get confidence scores.\n",
    "# We'll now give the prophet the test scrolls it has never seen before.\n",
    "# We only 'transform' here, we don't 'fit' again, as the prophet has already learned\n",
    "# its magical vocabulary from the training data.\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "prophecies = prophet.predict(X_test_vectorized)\n",
    "# This is the key fix: we get the probability for each prediction and find the max.\n",
    "confidence_scores = prophet.predict_proba(X_test_vectorized).max(axis=1)\n",
    "\n",
    "# Print the prophecies and their confidence.\n",
    "print(\"--- The Prophet's Final Report ---\")\n",
    "for raw_text, prophecy, confidence in zip(X_test, prophecies, confidence_scores):\n",
    "    print(f\"Ticket: '{raw_text}'\")\n",
    "    print(f\"Prophecy: '{prophecy}' (Confidence: {confidence:.2f}) \\n\")\n",
    "\n",
    "\n",
    "# 6. Evaluate the prophet's performance.\n",
    "# This final spell uses a 'classification_report' to show us how well\n",
    "# our prophet performed on the test data. This is the quantifiable evidence!\n",
    "print(\"\\n--- The Oracle's Final Judgement ---\")\n",
    "print(classification_report(y_test, prophecies, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b832c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
