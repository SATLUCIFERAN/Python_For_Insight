{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb49877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Oracle's Final Report on the Royal Decrees:\n",
      "\n",
      "                                     Original Decree  \\\n",
      "0  This is a brilliant new law that will bring pr...   \n",
      "1  The new decree is an absolute disaster; it wil...   \n",
      "2  The council's latest ruling seems to be entire...   \n",
      "3  This amazing new tax is going to fund our defe...   \n",
      "4  I'm extremely disappointed with the royal proc...   \n",
      "\n",
      "                          Cleaned & Lemmatized Words Sentiment Score   Verdict  \n",
      "0  brilliant new law bring prosperity entire kingdom            0.35  Positive  \n",
      "1  new decree absolute disaster surely cause rebe...            0.28  Positive  \n",
      "2  council latest ruling seems entirely neutral w...            0.25  Positive  \n",
      "3       amazing new tax going fund defense fantastic            0.38  Positive  \n",
      "4     extremely disappointed royal terrible decision           -0.88  Negative  \n"
     ]
    }
   ],
   "source": [
    "# The Linguist's Field Guide: Foundational Techniques\n",
    "# This script combines Tokenization, Cleaning, and Sentiment Analysis.\n",
    "\n",
    "# First, we load our essential tools.\n",
    "# TextBlob is our sentiment tool, and pandas helps us create our final report.\n",
    "# NLTK is our library for stopwords and lemmatizers.\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "\n",
    "# We'll use this list to store our findings.\n",
    "decree_reports = []\n",
    "\n",
    "# NLTK needs its data downloaded for the first time (run once per environment).\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)   \n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "# We'll load our list of English stopwords.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "# The Raw Artifacts: Our Fictional Decrees\n",
    "# -------------------------------------------------------------------------------------\n",
    "royal_decrees = [\n",
    "    \"This is a brilliant new law that will bring prosperity to the entire kingdom!\",\n",
    "    \"The new decree is an absolute disaster; it will surely cause a rebellion.\",\n",
    "    \"The council's latest ruling seems to be entirely neutral and without consequence.\",\n",
    "    \"This amazing new tax is going to fund our defenses against the dragons. It's fantastic!\",\n",
    "    \"I'm extremely disappointed with the royal proclamation. It's a terrible decision.\"\n",
    "]\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "# The Great Ritual: Performing our analysis on each decree.\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "for decree in royal_decrees:\n",
    "    # Step 1: Tokenization  (preserve_line avoids sentence tokenizer -> no punkt_tab error)\n",
    "    tokenized_words = word_tokenize(decree, preserve_line=True)\n",
    "\n",
    "    # Step 2: Text Cleaning (The Restoration Process)\n",
    "    # We apply lowercasing, punctuation removal, and stopword removal.\n",
    "    clean_words = []\n",
    "    for word in tokenized_words:\n",
    "        # Potion part 1: Only keep alphabetical words\n",
    "        if word.isalpha():\n",
    "            # Potion part 2: Lowercase the word\n",
    "            word = word.lower()\n",
    "            # Potion part 3: Remove stopwords\n",
    "            if word not in stop_words:\n",
    "                # Potion part 4 (Lemmatization): Find the true root\n",
    "                clean_words.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "    # Step 3: Sentiment Analysis\n",
    "    # We join our clean words back into a single sentence for the tool to read.    \n",
    "    cleaned_decree_string = \" \".join(clean_words)\n",
    "    blob = TextBlob(cleaned_decree_string)\n",
    "\n",
    "    # The 'sentiment.polarity' property gives us the final score.\n",
    "    polarity_score = blob.sentiment.polarity\n",
    "\n",
    "    # We then interpret the score to give a clear verdict.    \n",
    "    if polarity_score > 0.1:\n",
    "        verdict = \"Positive\"\n",
    "    elif polarity_score < -0.1:\n",
    "        verdict = \"Negative\"\n",
    "    else:\n",
    "        verdict = \"Neutral\"\n",
    "\n",
    "    # We bundle our findings into a neat scroll.    \n",
    "    decree_reports.append({\n",
    "        \"Original Decree\": decree,\n",
    "        \"Cleaned & Lemmatized Words\": \" \".join(clean_words),\n",
    "        \"Sentiment Score\": f\"{polarity_score:.2f}\",\n",
    "        \"Verdict\": verdict\n",
    "    })\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "# The Final Chronicle: Presenting the Report\n",
    "# -------------------------------------------------------------------------------------\n",
    "# We use pandas to organize our findings into a beautiful table.\n",
    "\n",
    "final_report_df = pd.DataFrame(decree_reports)\n",
    "print(\"The Oracle's Final Report on the Royal Decrees:\\n\")\n",
    "print(final_report_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98367a5b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
